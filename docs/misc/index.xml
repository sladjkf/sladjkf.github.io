<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Miscs on Nicholas Ruiyuan Wu</title>
    <link>http://localhost:1313/misc/</link>
    <description>Recent content in Miscs on Nicholas Ruiyuan Wu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="http://localhost:1313/misc/index.xml" rel="self" type="application/rss+xml" />
    
    
    
    <item>
      <title>jazz and math</title>
      <link>http://localhost:1313/posts/5_jazz_math/</link>
      <pubDate>Fri, 11 Apr 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/5_jazz_math/</guid>
      <description>&lt;p&gt;&lt;em&gt;Here&amp;rsquo;s a slightly rambly and somewhat pretentious post about my thoughts on the similarities between math and jazz.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I attended a lecture/Q&amp;amp;A session today at UMD given by the jazz bassist &lt;a href=&#34;https://en.wikipedia.org/wiki/Linda_May_Han_Oh&#34;&gt;Linda May Han Oh&lt;/a&gt;.
First of all, how cool is it that we have these preeminent musicians coming to UMD??? It&amp;rsquo;s not quite something I&amp;rsquo;m used to, and it feels like
a rare privilege to be able to listen to these musicians live; let alone hear their thoughts and experiences, live in the same room. It&amp;rsquo;s a nice break from my life in the math building, to go from my office of chalkboards and equations to the concert hall of grand pianos and stage lights.&lt;/p&gt;
&lt;p&gt;She started the session by having us listen to a few short clips of Mingus: &lt;a href=&#34;https://www.youtube.com/watch?v=tk71dhCz7wM&#34;&gt;&amp;ldquo;Myself When I Am Real (from Mingus Plays Piano)&amp;rdquo;&lt;/a&gt; and &lt;a href=&#34;https://www.youtube.com/watch?v=R-W2kKth5IE&#34;&gt;&amp;ldquo;Adagio ma non troppo (from Let My Children Hear Music)&amp;rdquo;&lt;/a&gt;. For me, first of all it was a blast to hear that again. I spent a lot of time listening to Let My Children Hear Music in high school, so it was somehow nostalgic to hear that again, immediately sensing the familiarity of that tune but not being able to quite place it (&amp;ldquo;ah, that&amp;rsquo;s Mingus!&amp;rdquo;) But it seemed like the point was to explain and elaborate her thoughts and approach as an improviser and composer - Mingus plays this &amp;ldquo;rough&amp;rdquo; thing on an instrument which isn&amp;rsquo;t his primary one, but comes up with this harmonic landscape that gets fleshed out into this grandiose orchestral realization on Adagio ma non troppo.&lt;/p&gt;
&lt;p&gt;The language that she used to describe that idea was something along the lines of &amp;ldquo;exploring the architecture of sound,&amp;rdquo; which was something that immediately captured my attention. Anyone who spends some serious time studying proof-based mathematics will eventually get some notion of the idea of a mathematical &amp;ldquo;structure&amp;rdquo; - an abstraction describing the essential data of an object or concept, describing what information is changed, destroyed, or preserved under transformations. I myself became very interested in the word &amp;ldquo;system&amp;rdquo; - a word that evokes the dynamics of independent things which come together and blend into a bigger picture, structure arising from an apparent lack thereof.&lt;/p&gt;
&lt;p&gt;And in some vague way I had noted that same thing in jazz - the circle of fifths, the sequences of 2-5-1s, all those important harmonic sequences that you learn when you first seriously study jazz, also come to bear in a similarly logical way. Improvisation - spontaneity within structure, structure within spontaneity. And when you go to a jam, you never really know how exactly things will go. Independent musicians coming together to form one sound, but everyone&amp;rsquo;s &lt;a href=&#34;https://www.youtube.com/watch?v=SVNKQtPvv00&amp;amp;t=22s&#34;&gt;personality shines through.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The thing that struck me today was that -&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;yeah, composers really DO think in this &amp;lsquo;mathematical&amp;rsquo; way&amp;rdquo;&lt;/em&gt; -&lt;/p&gt;
&lt;p&gt;this way of thinking of I&amp;rsquo;d only come into in the past few years -&lt;/p&gt;
&lt;p&gt;but also the continued reaffirmation of a belief I&amp;rsquo;ve held in the back of my head since high school.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Music can be a perfect blending of the intuitive and the logical, the emotional and the technical.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;That truly continues to fascinate me.&lt;/p&gt;
&lt;p&gt;Her approach was to take this narrative, or feeling - a story about my mother, the invisible threads that bind us together - these abstract ideas; ineffably humanistic - and take that as a grounds for improvisation or composition. And the process of taking something abstract and emotional, and turning it into real sounds, real textures, real &lt;em&gt;music&lt;/em&gt; seems amazingly cool to me. And the process of that looked like sitting in the front row of your own show, hearing and imagining the sound that you want to hear. That sort of compositional freedom also seemed so cool to me. I recall myself that when I&amp;rsquo;d try to take abstract ideas and make them into compositions, the result felt half-baked. I was reaching for sounds I couldn&amp;rsquo;t hear. There was a technical barrier.&lt;/p&gt;
&lt;p&gt;I did ask, &amp;ldquo;how did you reach that level or get past those technical barriers?&amp;rdquo; And I pretty much knew the answer, to be honest. I realized it almost at the same time I was asking it. Of course the only way to that is to assimilate that technique into your subconscious. Hours of listening and playing, getting the sounds in your ear and under your fingers. That way, when you need them, they&amp;rsquo;re there within your grasp. And then you can use them to write stories. Build worlds. You create your own vocabulary to describe the sounds, you build the mental maps needed to create music from feelings and narratives.&lt;/p&gt;
&lt;p&gt;I think there is something similar in mathematics. I am not so sure that mathematics is so unabashedly emotional; yet I do think that what we call &amp;ldquo;intuition&amp;rdquo; in mathematics is built by the same cognitive process. You stare at problems, you solve lots of them, you read lots of mathematics, and somehow your subconscious will intuit solutions to problems before your conscious brain does. (Indeed, I&amp;rsquo;ve found myself realizing that I can do some problem sets without really actively thinking about it now, almost on autopilot). Then, when you need them, your &amp;ldquo;bag of tricks&amp;rdquo; is ready at hand to be deployed. You build the mental maps needed to create proofs from hunches. (I guess this is what Terry Tao calls &lt;a href=&#34;https://terrytao.wordpress.com/career-advice/theres-more-to-mathematics-than-rigour-and-proofs/&#34;&gt;the post-rigorous stage&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;So in a sense to (only) focus on the structures and the techniques themselves feels like missing the bigger picture. The intuition you build from working with them and making them your own, coming up with your own way to feel around the space of possibilities afforded to you by those 12 notes is the prize one earns from hard work and diligent study. That feels like a kind of freedom to me. &lt;a href=&#34;https://youtu.be/SFVZG83f9xc?t=265&#34;&gt;&amp;ldquo;When you understand it yourself and make it a part of yourself, there is some great happiness in doing that.&amp;rdquo;&lt;/a&gt; And I guess whether I was doing jazz or doing math, that&amp;rsquo;s what I wanted in a sense - and continue to want. The sheer joy of uninhibited facility with a sound or an idea, seeing how far I can take it, like riding a bike down a hill and feeling the wind blow past you.&lt;/p&gt;
&lt;p&gt;One day I might be able to break through the barrier. More likely than not I will struggle with it for as long as I&amp;rsquo;m doing both. I think that&amp;rsquo;s the joy and the curse. There is always something new to do, some new sound to explore, some new idea to try.&lt;/p&gt;
&lt;p&gt;So in a sense, it&amp;rsquo;s been really good to have done a bit of both music and math. It sort of prevents you from getting narrow-minded about your discipline. Surely if these two seemingly disparate things seem to share something in common, then maybe there&amp;rsquo;s more I can learn from other fields, too. (I guess it&amp;rsquo;s really not that uncommon for STEM people to also be musicians, but&amp;hellip;)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Ok, so at the end of all that pretentious declaration, reality kicks in - and I have to just do my problem sets tomorrow. Haha. And therein lies another gap between the abstract and the concrete - the gap between the high-minded aesthetic idealism vs. the everyday grind. but that could be another blog post&amp;hellip;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Stochastic gradient estimation - two Markov chain examples</title>
      <link>http://localhost:1313/posts/4_stoch_grads/</link>
      <pubDate>Mon, 07 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/4_stoch_grads/</guid>
      <description>&lt;link rel=&#34;stylesheet&#34; href=&#34;https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css&#34; integrity=&#34;sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X&#34; crossorigin=&#34;anonymous&#34;&gt;
&lt;!-- The loading of KaTeX is deferred to speed up page rendering --&gt;
&lt;script defer src=&#34;https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js&#34; integrity=&#34;sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4&#34; crossorigin=&#34;anonymous&#34;&gt;&lt;/script&gt;
&lt;!-- To automatically render math in text elements, include the auto-render extension: --&gt;
&lt;script defer src=&#34;https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js&#34; integrity=&#34;sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa&#34; crossorigin=&#34;anonymous&#34;

    onload=&#34;renderMathInElement(document.body);&#34;&gt;&lt;/script&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Consider the following type of problem, first informally stated:&lt;/p&gt;
&lt;p&gt;We have a (stochastic) simulation model of a real-world process, for which we can control some input parameters. The performance of this process is measured by some sort of objective function, which we wish to optimize by changing the input parameters. This sort of problem abounds in applications; queueing theory is rife with such examples.&lt;/p&gt;
&lt;p&gt;More formally stated: suppose we have a discrete-time Markov chain \( (X_n)_{n=1}^\infty \) on a (continuous or discrete) state space \(\mathcal{X}\), for which the transitions are known. Suppose the transition kernel \(\mathbb{P}(X_{i+1} \mid X_i)\) is parameterized by a (in general vector-valued) parameter \(\theta\). Given a objective function \(J(x_1, x_2, \ldots, x_T)\), we want to maximize the quantity
$$
\mathbb{E}(g(X_1,X_2,\ldots, X_T))
$$
with respect to \(\theta\). Note that above, we are restricting ourselves to finite time-horizon performance measures, with time horizon \(T\).&lt;/p&gt;
&lt;p&gt;Thus, let \(\mathcal{X}^T = \mathcal{X} \times \ldots \mathcal{X}\), i.e tuples of length \(T\) in the product state space.&lt;/p&gt;
&lt;p&gt;A natural way to approach this would be to try to compute
$$
\frac{d\mathbb{E}(g(X_1,X_2,\ldots, X_T))}{d\theta}
$$
and use standard first-order methods for optimization to solve the problem. Clearly, this may not be tractable - there are many chains for which computing the expectation analytically would not be doable. An alternative approach is to try to construct &lt;em&gt;statistical estimators&lt;/em&gt; of this quantity, which is the basic idea of stochastic gradient estimation.&lt;/p&gt;
&lt;p&gt;Unbiased estimators can be obtained assuming that an interchange of differentiation and expectation (the integral) is justified. This is true for &amp;ldquo;sufficiently nice&amp;rdquo; objective functions \(g(\cdot)\) - a precise statement of sufficient conditions for this are given by the dominated convergence theorem. For example, if \(g\) is bounded, such an interchange would hold.&lt;/p&gt;
&lt;p&gt;Assuming that such an interchange holds, one has to consider where the parameter \(\theta\) appears in the expectation. Our focus right now is on examples where \(\theta\) appears most naturally in the transition kernel, i.e suppose that there is a family of distributions on the first \(T\) coordinates parameterized by \(\theta\):
$$
\theta \mapsto \mathbb{P}_{\theta}(X_1,\ldots,X_T)
$$
There are two approaches of interest in this case. For convenience, let us write a joint density \(f(x_1,\ldots, x_T;\theta)\) to represent the probability measure.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(1): The likelihood ratio/score function (LR/SF) approach.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Notice that the following identity holds by the chain rule of calculus:
$$
\frac{df(x_1,\ldots, x_T;\theta)}{d\theta} = \frac{d \log f(x_1,\ldots,x_n; \theta)}{d\theta} f(x_1,\ldots,x_n;\theta)
$$
Thus, assuming the aforementioned interchange of differentiation and integration is permissible,&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;amp;\frac{d\mathbb{E}(g(X_1,X_2,\ldots, X_T))}{d\theta} \\
&amp;amp;=
\int_{\mathcal{X}^T} g(x_1,\ldots, x_n) \frac{df(x_1,\ldots, x_T;\theta)} {d\theta}
\text{ d}x_1 \ldots \text{ d}x_T\\
&amp;amp;=
\int_{\mathcal{X}^T} g(x_1,\ldots, x_T)
\frac{d \log f(x_1,\ldots,x_T; \theta)}{d\theta}
f(x_1,\ldots,x_T; \theta)
\text{ d}x_1 \ldots \text{ d}x_T \\
&amp;amp;\approx \frac{1}{N}\sum_{(x_1,\ldots,x_T)}g(x_1,\ldots, x_T)
\frac{d \log f(x_1,\ldots,x_T; \theta)}{d\theta}
\end{aligned}
$$
i.e one can approximiate the gradient in a Monte-Carlo fashion by sampling \(x_1,\ldots,x_n\) according to the original measure \(f(x_1,\ldots, x_T)\) on the chain parameterized by \(\theta\), and plugging into the expression within the sum.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(2): The weak derivative approach.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Assume that the density \(f(x_1,\ldots,x_n;\theta)\) can be rewritten so that the following identity holds:
$$
\frac{df(x_1,\ldots, x_T;\theta)}{d\theta} = c(\theta)
\left[
f^{(1)}(x_1,\ldots, x_n;\theta) -
f^{(2)}(x_1, \ldots, x_n; \theta)
\right]
$$
A decomposition of this form is guaranteed to exist by the Hahn decomposition theorem. It is the so called &amp;ldquo;weak derivative&amp;rdquo; since this choice of \(f^{(1)}\) and \(f^{(2)}\) is in general nonunique. Then, the gradient can be approximated by simulating with respect to the measures \(f^{(1)}\) and \(f^{(2)}\).&lt;/p&gt;
&lt;p&gt;We wish to better understand these approaches by considering problems in which the solution is intuitively obvious, but can be rigorously solved by these approaches. To that end, we construct the following two examples.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;example-1-a-simple-discrete-state-markov-chain&#34;&gt;Example 1. A simple discrete-state Markov chain.&lt;/h2&gt;
&lt;p&gt;Consider the following three-state Markov chain on the space \(\mathcal{X}=\{0,1,2\}\) with the transition matrix parameterized by \(\theta \in (0,1)\):&lt;/p&gt;
&lt;p&gt;$$
P =
\begin{pmatrix}
1-\theta &amp;amp; \theta &amp;amp; 0\\
1- \theta &amp;amp; 0 &amp;amp; \theta \\
0 &amp;amp; 1-\theta &amp;amp; \theta
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;where the first row corresponds to \(0\), the second row corresponds to \(1\), and the third row corresponds to \(2\). In simple terms, the chain can be described as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;move right (or stay at \(2\)) with probability \(\theta\),&lt;/li&gt;
&lt;li&gt;move left (or stay at \(0\)) with probability \(1-\theta\).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let us suppose that \(X_0 = 0\). We want to consider maximizing the quantity \(\sum_{n=1}^T \rho^n X_i\) where \(\rho \in (0,1)\) is a discounting factor. It is intuitively clear that we should let \(\theta \rightarrow 1\) to maximize this quantity.&lt;/p&gt;
&lt;p&gt;In what follows, it will be convenient to write the transition kernel as a sum of indicators. We can do this for a finite-state Markov chain as follows:
$$
\mathbb{P}(X_{n+1} = x_{n+1} \mid X_n = x_n) = \sum_{i,j}1\{x_{n}=i, x_{n+1}=j\} P_{i,j}
$$
In our example, we can decompose the transition kernel into two terms:
$$
p(x_i,x_{i+1})
= (1-\theta)\sum_{
(i,j) \in A
} \mathbb{1}\{x_{i}  = i, x_{i+1}=j\}
+
\theta\sum_{(i,j) \in B}
\mathbb{1}\{x_{i}  = i, x_{i+1}=j\}
$$
where \( A = \{(0,0), (1,0), (2,1)\} \), \( B=\{(0,1),(1,2),(2,2)\} \).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The likelihood-ratio estimator.&lt;/em&gt; Now observe that we can write the expectation out as&lt;/p&gt;
&lt;p&gt;$$
\mathbb{E}\left[\sum_{i=1}^T \rho^n X_i\right] = \sum_{(x_1,\ldots,x_T) \in \mathcal{X}^T} \left(\sum_{i=1}^T \rho^n X_i\right)
p(x_0,x_1)\ldots p(x_{T-1},x_T)
$$&lt;/p&gt;
&lt;p&gt;So the measure is over paths of length \(T\). Taking the derivative of the log gives the estimator of the form&lt;/p&gt;
&lt;p&gt;$$
\left(\sum_{i=1}^T \rho^n X_i\right) \frac{d}{d\theta} \log(p(X_0,X_1)\ldots p(X_{T-1},X_T))=
\left(\sum_{i=1}^T \rho^n X_i\right) \left(\sum_{i=1}^T \frac{d}{d\theta}\log p(X_{i-1},X_i)\right)
$$&lt;/p&gt;
&lt;p&gt;$$
\frac{d}{d\theta}\left[\log p(X_{i-1}, X_i)\right] = \frac{\frac{d}{d\theta}[p(X_{i-1},X_i)]}{p(X_{i-1},X_i)} =
\frac{
-\sum_{
(i,j) \in A
} \mathbb{1}\{X_{i}  = i, X_{i+1}=j\}
+ \sum_{(i,j) \in B}
\mathbb{1}\{X_{i}  = i,
X_{i+1}=j\}
}{
(1-\theta)\sum_{
(i,j) \in A
} \mathbb{1}\{X_{i}  = i, X_{i+1}=j\}
+
\theta\sum_{(i,j) \in B}
\mathbb{1}\{X_{i}  = i, X_{i+1}=j\}}
$$&lt;/p&gt;
&lt;p&gt;$$
\frac{d\widehat{J}(X_1,\ldots, X_T)}{d\theta}=\left(\sum_{i=1}^T \rho^n X_i\right)
\left(
\sum_{n=0}^{T-1}
\frac{ -\sum_{
(i,j) \in A
} \mathbb{1}\{X_{n}  = i, X_{n+1}=j\}
+ \sum_{(i,j) \in B}
\mathbb{1}\{X_{n}  = i, X_{n+1}=j\}
}{
(1-\theta)\sum_{
(i,j) \in A
} \mathbb{1}\{X_{n}  = i, X_{n+1}=j\}
+
\theta\sum_{(i,j) \in B}
\mathbb{1}\{X_{n} = i, X_{n+1}=j\}}
\right)
$$&lt;/p&gt;
&lt;p&gt;This can be estimated in an actual simulation setting by simulating paths \((x_0, x_1,\ldots, x_T)\), and doing Monte-Carlo to find the expected value, which is equivalent to \(\frac{d\mathbb{E}(J(X_1,\ldots,X_T))}{d\theta}\). This estimator has an intuitive interpretation in the following sense:
$$
\left(\text{realized cost over the path given } \theta\right)
\left(
\frac{-(\text{number of left moves})}{1-\theta}
+
\frac{\text{number of right moves}}{\theta}
\right)
$$
When I realized that the estimator had the above form, I was reminded of gradient estimators used in reinforcement learning. Indeed, when applied to Markov Decision Processes (MDPs) with policies of parametric form \(\pi_\theta\), the likelihood-ratio technique for finding the parameters of the optimal policy in the class of parameterized parameters is called REINFORCE - the canonical reference is &lt;a href=&#34;https://link.springer.com/article/10.1007/bf00992696&#34;&gt;Williams (1992)&lt;/a&gt;. Interestingly, it seems that the literature from the simulation optimization community and the reinforcement learning community on this topic have developed in parallel; Williams&amp;rsquo; paper primarily seems to reference previous papers on RL and does not directly reference simulation optimization papers on stochastic gradient estimation (although such works appeared prior to Williams&amp;rsquo;, e.g this expository article by &lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/84537.84552&#34;&gt;Glynn (1990)&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;In practice, one faces several challenges in using an estimator of this type. The primary challenge is &lt;em&gt;controlling variance&lt;/em&gt; to limit the amount of computation necessary to get good gradients. It&amp;rsquo;s readily observed that there is a blowup when \(\theta\) is close to 1 or 0, and the variance will also grow with respect to the time horizon. A naive way of mitigating the variance dependent on the time horizon is to decrease the discounting factor \(\rho\), but in general techniques from Monte-Carlo variance reduction can be applied (e.g common random numbers, quasi-Monte-Carlo, etc.)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The weak derivative estimator.&lt;/em&gt;
The weak-derivative estimator for a path of length \(T&amp;gt;1\) doesn&amp;rsquo;t seem straightforward to derive, as it requires direct differentiation of the product of transitions \(p(x_0,x_1)\ldots p(x_{T-1},x_T)\) (in which there will be a lot of terms). It is still somewhat instructive to see what happens for \(p(x_0, x_1)\) - the decomposition into two measures is apparent from the above calculations:&lt;/p&gt;
&lt;p&gt;$$
\sum_{(i,j) \in B}
\mathbb{1}\{x_{i}  = i,
x_{i+1}=j\}
-\sum_{
(i,j) \in A
} \mathbb{1}\{x_{i}  = i, x_{i+1}=j\} =
p_1(x_i,x_{i+1}) - p_2(x_i,x_{i+1})
$$&lt;/p&gt;
&lt;p&gt;These correspond to the difference of two deterministic measures, one in which you only move left and one in which you only move right. The gradient would be the performance difference from following one vs. the other. Notice already that this would require simulating two different version of the chain if there was a remaining stochasticity dependent on \(\theta\), but in this case since the resulting measures are degenerate there is no simulation required when \(T=1\). In general, though, one could imagine running \(2^T\) versions of the chain where we replace each \(n\)th step by a deterministic move left or right, which would be prohibitively expensive.&lt;/p&gt;
&lt;h2 id=&#34;example-2-dependence-on-a-continuous-initial-state&#34;&gt;Example 2. Dependence on a continuous initial state.&lt;/h2&gt;
&lt;p&gt;Consider a chain which describes the following sort of process.&lt;/p&gt;
&lt;p&gt;A game is played as follows. You, the participant, choose a time budget in the compact interval \([0,M]\). I, the game&amp;rsquo;s host, give you tasks to complete which take a random amount of time at each discrete timestep \(t=0,1,2,\ldots\), which represents the current round. The time it takes to complete a task is an \(\text{Exp}(\lambda)\) random variable. The game ends when you run out of time. We consider the following two questions:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(1). On average, what is the expected number of rounds that one survives?&lt;/em&gt;
&lt;em&gt;(2). How should one choose the time budget to maximize the number of rounds they survive?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The answer to &lt;em&gt;(1)&lt;/em&gt; is not immediately obvious, but the answer to &lt;em&gt;(2)&lt;/em&gt; is: you should choose \(M\). Even though one might be able to analytically compute the solution to &lt;em&gt;(1)&lt;/em&gt; and thus the answer to &lt;em&gt;(2)&lt;/em&gt;, to illustrate the ideas of gradient estimation we shall try to derive an estimator.&lt;/p&gt;
&lt;p&gt;A formal specification of the chain is:&lt;/p&gt;
&lt;p&gt;$$
\mathcal{X} = \mathbb{R}
$$
$$
X_0 = \theta
$$
$$
X_{i+1} = \max(X_i - \Delta_i,0)
$$
$$
\Delta_i \sim Exp(\lambda) \hspace{0.2cm} \text{(i.i.d})
$$
$$
J(X_1,\ldots) = \inf\{n\in \{0,1,\ldots\}\mid X_n = 0\}
$$&lt;/p&gt;
&lt;p&gt;The objective, \(J\), is a discrete random variable. Assuming the interchange of summation and differentiation is justified (which it is, to be shown shortly), we may write&lt;/p&gt;
&lt;p&gt;$$
\mathbb{E}(J) = \sum_{j=0}^\infty j \mathbb{P}(J(X_1,\ldots,) = j)
$$
$$
\frac{d\mathbb{E}(J)}{d\theta} = \sum_{j=0}^\infty j \frac{d\mathbb{P}(J(X_1,\ldots,) = j)}{d\theta}
$$&lt;/p&gt;
&lt;p&gt;In fact, \(J-1\) is \(\text{Poisson}(\theta\lambda)\). This can be intuitively seen as follows: at least one step must be taken till the game ends, so \(J\) is at least one. Recall that a \(\text{Poisson}(\theta\lambda)\) variable may be interpreted as the number of arrivals in a time interval of length \(\theta\) with interarrival time distributed as \(\text{Exp}(\lambda)\).  If there are no arrivals in the time interval \(\theta\), the first arrival (or task) took more than \(\theta\) time to complete. If there is one arrival in the time interval \(\theta\), the first task was completed within \(\theta\) time but the second task took the remaining time to complete, etc.&lt;/p&gt;
&lt;p&gt;To prove this (by manipulating the PDFs), we observe that \(J\) is the first time that the sum of the increments \(\sum_i \Delta_i\) exceeds \(\theta\). The probability that this time is equal to \(j\) is
$$
\mathbb{P}(\sum_{i=1}^{j-1} \Delta_i&amp;lt;\theta, \Delta_j &amp;gt; \theta - \sum_{i=1}^{j-1} \Delta_i)
= \int_0^\theta\int_{\theta-s}^\infty f_S(s)f_Y(y)\text{ dy} \text{ ds}
$$
where we let \(S \sim \text{Erlang}(j-1,\lambda)\) and \(Y \sim \text{Exp}(\lambda)\). After one does this integral, we obtain a Poisson PMF. By this point, we know the expectation and its derivative: \(\mathbb{E}(J) = \lambda \theta\), \(\frac{d \mathbb{E}(J)}{d\theta} = \lambda\) so the solution is quite clear.&lt;/p&gt;
&lt;p&gt;From this, the LR estimator becomes
$$
X\left(\frac{X}{\theta} - \lambda\right)
$$
where \(X \sim \text{Poisson}(\lambda \theta)\).&lt;/p&gt;
&lt;p&gt;While this example turned out to be quite straightforward, it illustrates that the dependence of the chain on initial conditions can sometimes naturally appear within the probability measure rather than within the objective function \(J\), and that obtaining the exact form of this dependence may take a little thought. It may not be obvious where the parameter appears, and where the parameter appears and how the output variable depends on the parameter will affect the natural choice of which type of estimator to use.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;References.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Fu, Michael C. Stochastic gradient estimation. Springer New York, 2015. &lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-1-4939-1384-8_5&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Talk slides: concentration inequalities</title>
      <link>http://localhost:1313/posts/3_stat_rit_talk/</link>
      <pubDate>Fri, 13 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/3_stat_rit_talk/</guid>
      <description>&lt;link rel=&#34;stylesheet&#34; href=&#34;https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css&#34; integrity=&#34;sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X&#34; crossorigin=&#34;anonymous&#34;&gt;
&lt;!-- The loading of KaTeX is deferred to speed up page rendering --&gt;
&lt;script defer src=&#34;https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js&#34; integrity=&#34;sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4&#34; crossorigin=&#34;anonymous&#34;&gt;&lt;/script&gt;
&lt;!-- To automatically render math in text elements, include the auto-render extension: --&gt;
&lt;script defer src=&#34;https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js&#34; integrity=&#34;sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa&#34; crossorigin=&#34;anonymous&#34;

    onload=&#34;renderMathInElement(document.body);&#34;&gt;&lt;/script&gt;
&lt;p&gt;I recently gave a short talk at UMD&amp;rsquo;s RIT (Research Interaction Team) on basic tail inequalities involving subgaussian and subexponential random variables. The slides are below (unannotated and annotated).&lt;/p&gt;
&lt;h2 id=&#34;unannotated&#34;&gt;Unannotated&lt;/h2&gt;
&lt;iframe src=&#34;https://drive.google.com/file/d/1Eq986GOjphmTzVV_2Su7w3wFBZnNWTz4/preview&#34; width=&#34;640&#34; height=&#34;480&#34; allow=&#34;autoplay&#34;&gt;&lt;/iframe&gt;
&lt;h2 id=&#34;annotated&#34;&gt;Annotated&lt;/h2&gt;
&lt;iframe src=&#34;https://drive.google.com/file/d/1eSlwk_Vj7K0E6VnbMBw-o8GdAjG1QdHO/preview&#34; width=&#34;640&#34; height=&#34;480&#34; allow=&#34;autoplay&#34;&gt;&lt;/iframe&gt;
</description>
    </item>
    
    
    
    <item>
      <title>My first year of grad school</title>
      <link>http://localhost:1313/posts/2_first_year_grad_school/</link>
      <pubDate>Tue, 28 May 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/2_first_year_grad_school/</guid>
      <description>&lt;link rel=&#34;stylesheet&#34; href=&#34;https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css&#34; integrity=&#34;sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X&#34; crossorigin=&#34;anonymous&#34;&gt;
&lt;!-- The loading of KaTeX is deferred to speed up page rendering --&gt;
&lt;script defer src=&#34;https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js&#34; integrity=&#34;sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4&#34; crossorigin=&#34;anonymous&#34;&gt;&lt;/script&gt;
&lt;!-- To automatically render math in text elements, include the auto-render extension: --&gt;
&lt;script defer src=&#34;https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js&#34; integrity=&#34;sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa&#34; crossorigin=&#34;anonymous&#34;

    onload=&#34;renderMathInElement(document.body);&#34;&gt;&lt;/script&gt;
&lt;p&gt;I just recently finished my first year of grad school at the University of Maryland. As I&amp;rsquo;ve been taking some time to recover from the madness of the spring semester, I figured it might actually be good to write a few things about my experience with it, and finally make a post on my thus-far under-utilized website! After all, an aspiring academic can always use more practice writing (at least &lt;a href=&#34;https://matt.might.net/articles/successful-phd-students/&#34;&gt;Matt Might says so.&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m writing this to sort of give myself a big-picture view of how things went and so I can piece together the narrative of how things are going. If you read this and you find it helpful, let me know! My email is on the homepage.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;coursework&#34;&gt;coursework&lt;/h3&gt;
&lt;p&gt;At UMD, first-year graduate students in the AMSC (Applied Math and Scientific Computation) program have the option of deciding between the Scientific Computing (SC) or the Applied Math (AM) track. In short, the SC track is less flexible in terms of coursework but doesn&amp;rsquo;t require qualifying exams; the AM track is more flexible but requires qualifying exams.&lt;/p&gt;
&lt;p&gt;Being unsure, I opted for the first-year sequence of Scientific Computing I and II (which also counts as a coursework-based qualifying exam for the Applied Math track). However, ever since I&amp;rsquo;d taken (non-measure theoretic) courses on stochastic processes and real analysis in undergrad, I wanted to learn measure-theoretic probability. Convex optimization had also been a topic I&amp;rsquo;d wanted to learn since doing research that used optimization tools, so I excitedly added it to my schedule.&lt;/p&gt;
&lt;p&gt;Thus, my first year schedule ended up looking like this:&lt;/p&gt;
&lt;center&gt;
&lt;style type=&#34;text/css&#34;&gt;
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-u0o7{border-color:inherit;font-weight:bold;text-align:left;text-decoration:underline;vertical-align:top}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
.tg .tg-0lax{text-align:left;vertical-align:top}
&lt;/style&gt;
&lt;table class=&#34;tg&#34;&gt;&lt;thead&gt;
  &lt;tr&gt;
    &lt;th class=&#34;tg-u0o7&#34;&gt;Fall 2023&lt;/th&gt;
    &lt;th class=&#34;tg-u0o7&#34;&gt;Spring 2024&lt;/th&gt;
  &lt;/tr&gt;&lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-0pky&#34;&gt;Sci Comp I&lt;/td&gt;
    &lt;td class=&#34;tg-0pky&#34;&gt;Sci Comp II&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-0pky&#34;&gt;Prob I&lt;/td&gt;
    &lt;td class=&#34;tg-0pky&#34;&gt;Parallel Comp.&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-0pky&#34;&gt;Convex Opt.&lt;/td&gt;
    &lt;td class=&#34;tg-0pky&#34;&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;TA: Linear Algebra&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;TA: Intro to Prob&lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/center&gt;
&lt;p&gt;The fall semester was a bit of a wake-up call to some extent. Moments that I remember include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For Prob, I had enough background in analysis to do the problem sets after hours of struggle and StackExchange posts. But, even after that, when I got to the midterm exam and got seemingly simple questions like:&lt;br&gt;
&amp;ldquo;Let \(\eta \rightarrow a\) and \(\xi \rightarrow b\) (both in probability), where \(a,b\) are nonzero constants, and \(\eta,\xi\) are zero only on a set of measure zero. Show that \(\eta/\xi \rightarrow a/b\) in probability.&amp;rdquo; &lt;br&gt;
It&amp;rsquo;s trivial if you know the &lt;a href=&#34;https://en.wikipedia.org/wiki/Continuous_mapping_theorem&#34;&gt;continuous mapping theorem&lt;/a&gt;, but we hadn&amp;rsquo;t been taught that. At the end of the day we got to take it home since all of us did so badly during the in-class portion of the exam.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In Convex Optimization, numerous topics would appear on the homework that hadn&amp;rsquo;t been taught in class (e.g subgradients), and vague questions like &amp;ldquo;Would this choice of function be reasonable? Propose some conditions that would be appropriate&amp;rdquo; also appeared.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In Sci Comp I, I did well on all the HWs through the class, only to get a B grade overall due to my grade on the final. This meant I would have to get an A or better in the subsequent classes in the sequence to get qual credit.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I initially felt frustrated by these moments. &amp;ldquo;Why hadn&amp;rsquo;t we been taught these things? Why is the grading this way? Why can&amp;rsquo;t this be more specific?&amp;rdquo; To some extent, though, I began to appreciate that the standard for me as a graduate student was going to have to be higher than what I had in undergrad.&lt;/p&gt;
&lt;p&gt;Grad students (or, at least aspiring academics) need to be capable of reading and learning on their own when they encounter problems they don&amp;rsquo;t know how to solve, and quickly learn techniques for solving those problems from the appropriate references. That&amp;rsquo;s how research is, after all&amp;hellip; you are trying to solve a problem that hasn&amp;rsquo;t exactly been solved before, and perhaps turn a somewhat ill-defined question into a precise mathematical statement.&lt;/p&gt;
&lt;p&gt;Another conclusion - taking three classes is (generally) too much. I thought I could power through like I did in undergrad, but&amp;hellip; no. Core grad courses are significantly harder, and TA duties (which did not exist in undergrad for me) also can be thought of as an additional class. During the final exam period, you not only have to take your own exams but also grade the finals of your students. I was so busy that I could not allocate the appropriate amount of effort to do well in all my classes. This has its consequences, especially when you&amp;rsquo;re taking core courses that you need to do well in (see above).&lt;/p&gt;
&lt;p&gt;I wisened up and only took 2 courses the following semester (no more excitedly adding classes to my schedule). That turned out to be better - I was able to spend more time on my core course and get the grades I needed to fulfill the qual credit requirement. Still, though, the spring semester was also stressful - the TA work turned out to be more involved than expected as compared to the previous semester. This is just since there is some variance from course to course.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;teachingtaing&#34;&gt;teaching/TAing&lt;/h3&gt;
&lt;p&gt;On the other hand, teaching for me has been a mix of ups and downs.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I discovered I really love lecturing. As a TA for Linear Algebra and Intro to Prob, I only had to do 50-minute discussions sections where I reviewed the course content and did example problems. I love being able to share my insight into the topics and help the students try to get a better handle on things, and I find the challenge of presenting the problems and content in a logical and organized way to be a delight. The real-time feeling of having students in front of me while I scratch away at the chalkboard definitely also keeps me engaged.&lt;/li&gt;
&lt;li&gt;I love having an excuse to make awful jokes. (&amp;ldquo;Hey guys, today we&amp;rsquo;re learning about the &lt;a href=&#34;https://en.wikipedia.org/wiki/Central_limit_theorem&#34;&gt;CLT&lt;/a&gt;&amp;hellip; you know, chicken, lettuce, and tomato&amp;rdquo;). Sometimes they smile. Mostly they don&amp;rsquo;t, because they&amp;rsquo;re awful jokes. It amuses me, though.&lt;/li&gt;
&lt;li&gt;On the other hand, I really don&amp;rsquo;t like grading. It&amp;rsquo;s tedious work, and deciding on how many points to give what portion of the work can feel quite arbitrary. I also don&amp;rsquo;t feel at ease when I give people bad grades; knowing that my actions can really make or break my students&amp;rsquo; days. The grading turnaround for exams is also quite tight - I had to skip some of my own classes to make the turnaround for some weeks.&lt;/li&gt;
&lt;li&gt;Logistically, coordinating student work for a large-lecture class (even with several TAs) can become a headache as papers need to be shuffled back and forth between offices. I became a huge fan of Gradescope for this reason.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I guess my position can be summarized as &amp;ldquo;I like the actual teaching part but not the paperwork part.&amp;rdquo; That&amp;rsquo;s probably a very common opinion.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;quals&#34;&gt;quals&lt;/h3&gt;
&lt;p&gt;I took one qualifying exam after my fall semester, the qualifying exam in Probability. Initially, I was somewhat apprehensive about it since I only had taken half of the required course sequence (Prob I), but I told myself &amp;ldquo;I have to try. Worst case, I fail and I have to do it again, but now I know what it&amp;rsquo;s like. Best case, I pass.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;I studied primarily from &lt;a href=&#34;https://services.math.duke.edu/~rtd/PTE/PTE5_011119.pdf&#34;&gt;Durrett&amp;rsquo;s book&lt;/a&gt;. I found it to be an easier read than Koralov and Sinai, which is the book used in UMD&amp;rsquo;s probability courses. Compared to Koralov and Sinai, Durrett is slightly more chatty and gives more examples, which I think makes for a better exposition. If I had more time, I probably would have also looked to &lt;a href=&#34;https://link.springer.com/book/10.1007/978-1-4684-9305-4&#34;&gt;Steele&amp;rsquo;s book on stochastic calculus&lt;/a&gt; to really nail down martingales, martingale convergence, Brownian motion, and stochastic integrals. There&amp;rsquo;s some more reading to do&amp;hellip;&lt;/p&gt;
&lt;p&gt;I prepared by just doing as many problems from the old qualifying exams as I could. Some of them I couldn&amp;rsquo;t even solve (I still don&amp;rsquo;t know how to do stochastic integration). There were also no official solutions at the time I was studying, so I was sort of in the dark as to whether I was doing things right. I really should have asked some more senior students if they had answer sheets for the old exams, though&amp;hellip;&lt;/p&gt;
&lt;p&gt;I didn&amp;rsquo;t try to waste too much time carefully learning the content. If I had more time and I knew what I was doing; it definitely would have been better to carefully read and learn - but for the exam, I tried to focus on patterns - &amp;ldquo;ok, I definitely gotta use dominated convergence for this one. ok, this one is a limit theorem question&amp;rdquo; - and just tried to get a handle on how to apply the basic tools.&lt;/p&gt;
&lt;p&gt;Apparently it worked well enough. I got a 36/60, which was the bare minimum passing score for this exam.  But, as others told me, &amp;ldquo;nobody is going to ask what you got on the qual - it only matters that you passed.&amp;rdquo; Amusingly, I also heard &amp;ldquo;that&amp;rsquo;s actually optimal because it means you didn&amp;rsquo;t study more than you needed to.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;This result pretty much cemented my decision to follow the Applied Math track.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;research&#34;&gt;research&lt;/h3&gt;
&lt;p&gt;I tried to get started doing research and reading papers, but it was incredibly hard to find time and energy to do so on top of both the teaching and classwork committments. I sort of get the impression that the typical path is to focus on classwork for the first two years, then transition into research, but I wanted to get right into thinking about the bigger picture as soon as possible.&lt;/p&gt;
&lt;p&gt;Specifically, I started reading about multi-agent reinforcement learning, which I found to be a pretty fascinating and mathematically rich area of research. I learned some basic game theory, a small smattering of some proper complexity theory, and got to realize that there are some interesting applications of probability theory and PDEs to strategic interactions. I got a teeny bit of the big picture, but I don&amp;rsquo;t even completely understand that. My goal is to do some more reading this summer.&lt;/p&gt;
&lt;p&gt;Still, I think I&amp;rsquo;ve learned some things about the way I tend to read papers that I need to work on. For example, I have a tendency to handwave and just hope the details work out. In other words, I&amp;rsquo;m not careful enough. This is probably a bad holdover from handwavy arguments on my homework.&lt;/p&gt;
&lt;p&gt;To fix this habit, I need to get into the habit of being critical and asking questions to myself.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;Why does this matter?&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Can you prove this?&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Do you really understand what this term/definition means?&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In my meetings where I would explain what I learned, I would get questions that I didn&amp;rsquo;t know how to answer. I would dimly realize that I had thought about this, but not to the level that was actually sufficient to confidently and quickly answer the concerns that were raised.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;life&#34;&gt;life&lt;/h3&gt;
&lt;p&gt;I overall had a great time hanging out with my fellow grad students - everyone in the department at UMD is quite friendly. It was honestly really great to meet everyone the first few days and hear about the diverse set of research interests and backgrounds we all had. At first, it was honestly sometimes intimidating hanging out with other students who had more comprehensive backgrounds than I did, but I quickly realized that everyone was overall pretty relaxed and accomodating. I&amp;rsquo;d always felt a bit inadequate in the sense that I didn&amp;rsquo;t (and still don&amp;rsquo;t) have the most comprehensive pure math background, but I realized that everyone has their own strengths and interests - and that&amp;rsquo;s alright. I learned that it&amp;rsquo;s better to ask questions, show interest, and find common ground (espectially outside of just math), rather than be scared that I don&amp;rsquo;t know enough to hold a conversation.&lt;/p&gt;
&lt;p&gt;On the other hand, I became aware that some of my peers actually looked up to me in the same way that I looked up to others, which was a funny realization. It seems that no matter how highly we achieve, we&amp;rsquo;re all going through similar experiences internally. That brought me back to earth. Math isn&amp;rsquo;t everything; it may be a large part of my life, but not necessarily the whole world to me. At the end of the day, we&amp;rsquo;re all just people connecting over shared interests and common experiences.&lt;/p&gt;
&lt;p&gt;We had a cohort struggling through the Sci Comp I/II sequence together, which made the experience significantly more bearable. We were able to share hints and strategies for attacking some of the HW problems in our shared office, which helped us get through the weekly homework.&lt;/p&gt;
&lt;p&gt;Just trying to also stay on top of the things that I needed to to continue living (like cooking for myself, cleaning, etc.) also took more time and energy than expected. It got somewhat demoralizing sometimes when after a long day of teaching and coursework, I remembered I had to get groceries. I also had to deal with seemingly random inconveniences like roaches and having my car damaged from a theft attempt. These were all ultimately resolvable, but felt demoralizing at the time.&lt;/p&gt;
&lt;p&gt;All these stressors resulted in several weeks where I had to keep telling myself &amp;ldquo;You gotta keep it together&amp;rdquo; just to make it through. It really made me realize that I actually do need to take time for myself, and spend time with the people I care about, and do the things I love besides just math. Seems obvious, right? But it was easy to forget when I was in the thick of things.&lt;/p&gt;
&lt;p&gt;On a slightly brighter note, I took up bike commuting to save on gas and parking dollars. This year, I hit a total of 1000 miles on my electric bike, and probably more that weren&amp;rsquo;t logged on my non-electric bike. I think that was a fun achievement. It also helped me get some exercise that I would have absolutely neglected if I were only commuting by car.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;conclusion&lt;/h3&gt;
&lt;p&gt;I went in feeling pretty hyped to do math and I came out the first year feeling pretty tired and in need of a break. That&amp;rsquo;s normal; I think. At least they tell me the first year is the hardest. I don&amp;rsquo;t know if I entirely believe that, but I&amp;rsquo;m willing to go along with it for now.&lt;/p&gt;
&lt;p&gt;My lessons learned (and favorite advice for myself) from this experience so far would probably be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Don&amp;rsquo;t be afraid.&lt;/strong&gt; I wouldn&amp;rsquo;t have been able to pass the quals, or learn as much as I did this year, if I remained afraid of people who knew more than me, or was scared of taking a class in something I didn&amp;rsquo;t really know as well. I wouldn&amp;rsquo;t have gotten started with reading if I was scared to reach out.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Always keep the big picture in mind.&lt;/strong&gt; A piece of advice from my old mentor back at UVA. I feel like this is good advice for both research and life. To write a good article, you have to know what the overarching story is. To keep going through grad school, you have to keep telling yourself a story of why you are here and why this is worthwhile. (There were many moments where I questioned why I was doing this.)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Be critical and careful.&lt;/strong&gt; To make a good story, you have to know all the details and make sure everything is right. You still have to know how all the details fit into the big picture and work at both scales.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A support network is critical.&lt;/strong&gt; Having people you can talk to when things get too hard helps immensely.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    
    
    <item>
      <title>First post</title>
      <link>http://localhost:1313/posts/1_my_first_post/</link>
      <pubDate>Tue, 02 May 2023 11:31:40 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/1_my_first_post/</guid>
      <description>&lt;p&gt;This is mostly just a test of the posting functionality for this website&amp;hellip; hopefully more actual content to come soon! I&amp;rsquo;m thinking of using this page to write some stuff about what I&amp;rsquo;ve been studying and thinking about, and with more time coming up as my undergrad ends, I&amp;rsquo;ll be able to find time to do so.&lt;/p&gt;
</description>
    </item>
    
    
    
    
    
    
    
    
    
    
  </channel>
</rss>
